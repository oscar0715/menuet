---
title: Collaborative Filtering for Implicit Feedback Datasets
mathjax: true 
tags:
  - Algorithm
categories:
  - Technology
  - Algorithm
date: 2018-05-17 17:24:45
---

Collaborative Filtering for Implicit Feedback Datasets

<!-- more -->

***


# Abstract
推荐系统通过分析用户在平台上留下的行为（隐式反馈），对用户做个性化的推荐，以提高用户体验。系统被动地追踪不同的用户行为，包括，购买历史，浏览习惯，来对用户偏好进行建模。不同于被更加广泛研究的显性反馈信息，我们没有关于用户偏好的直接信息，特别是，我们没有足够的证据来判断用户对某个商品不喜欢。所以，我们需要找到隐式反馈数据集的独特属性。我们建议，把隐式反馈的数据集和不同的置信度作为判断用户对商品正向偏好和负向偏好的证据（Indication）。这也就是要建立一个为隐式反馈推荐定制的因子模型（factor model）。我们同样推荐了一种可伸缩（scalable）的优化策略，使得算法的复杂度可以和数据集的大小呈线性关系。这个算法被成功用在了电视剧推荐系统中，可以和其他已知的算法相媲美。另外，我们还为该推荐系统的推荐提供了一种创新的解释

# Introduction
电商正在飞速的发展中，所以一个重要的挑战就是如何帮助用户从数量众多的商品去帮助用户找到他们最想要的商品。推荐系统就是解决这个问题的一个重要工具。推荐系统的背后是建立用户画像和商品的模型，然后找到如何联系两者的方法。

更广泛而言，推荐系统是基于两种不同的策略。

第一种是基于内容的策略（content based approach）
对每个用户和商品都建立一个画像，举个例子，一部电影的画像，包括了它的风格，演员，票房等属性。一个用户画像则包括了人口信息，或者问卷调差的结果。算法就可以通过这些画像来做用户和商品的匹配，但是这需要收集一些关于用户的额外数据，这些数据并不容易收集。

>笔记：收集隐性数据要比收集显性数据要难

另一种策略是，也是我们重点讨论的，依赖于过去的用户在平台上发生的行为，而不需要建立显性的用户画像。这种方法就是协同过滤的方法（这个名字是第一个推荐系统Tapestry的开发者创造的）。协同过滤分析（CF）的是用户物品之间的相关关系，来确定用户和物品之间的联系。例如，一些协同过滤推荐系统可以找出相似的商品配对，或者有购买记录的两个用户，来进一步推测未知的用户和物品之间的联系。其中，唯一需要的信息就是过去的用户行为。CF还有一个优势是不需要任何领域知识。所以当数据集难以用基于内容的策略来建立画像的时候，CF是一个很好的方案。但是虽然CF的精准度通常比基于内容的方案更高，但是CF无法解决冷启动的问题，也就是说，每当上架一个新商品，这个商品无法进入推荐。

>笔记：冷启动有两方面，一方面是新用户，一方面是新数据

推荐系统依赖于不同的输入信息。最直接的输入信息，就是高质量用户的显性偏好，比如，用户对商品的主动评分。Netflix 就是如此，收集用户对电影和电视剧的评分来作为用户的偏好信息。但是显性偏好通常都不容易获取，所以推荐系统可以利用更丰富的用户行为作为隐性反馈（implicit feedback），间接地推断用户的偏好。隐形反馈包括购买历史，浏览记录，搜索习惯，甚至是鼠标的移动。举个例子，如果用户买了同一个作者的很多书，那么可能意味着这个用户是喜欢这个作者的。

在推荐领域内，大部分的论文都是研究如何处理显性反馈，可能是因为这样的数据使用起来很方便。但是在很多实际场景中，推荐系统需要以隐性反馈信息为核心。因为用户可能不愿意主动给商品打分，或者系统本身就无法获得用户的显性反馈在一个。在隐性反馈模型中，只要用户允许系统去收集用户信息，系统就不需要额外的显性反馈信息了。

这篇论文就是研究适合处理隐性信息的算法，介绍了我们在建立了一个对电视节目的推荐系统过程中的的获得的一些经验。这个系统从建立之初开始，就只使用隐性的反馈信息，分析匿名用户的看视频的行为。

此时，很重要的一件事情就是搞清楚隐性信息的独特特性：
1. 没有负反馈。
    通过观察用户行为，我们可以推测用户可能喜欢或者可能会购买的东西。但是我们无法得知用户是不是不喜欢这个商品。比如说，用户没有看这个视频，可能是因为他不喜欢这个视频，或者可能只是他不知道有这个视频。这种不对称性在显性反馈的系统中是不存在的。
    这里呢，就有很多隐喻。显性反馈系统的重点在于收集用户的信息（用户对商品的评分），这些信息提供了正反馈和负反馈。在显性反馈系统中，大部分的数据是缺失的，这些数据需要在系统分析的过程中被剔除。这在隐形反馈系统中是不可能的，因为隐性反馈系统只收集用户的正反馈信息，这样分析出来的画像有很大的偏颇。因此，很重要的一件事情就是处理缺失数据，就是说，我们如何收集用户的的负反馈隐性信息。
2. 隐形反馈信息本质上就是夹带噪音的。
    因为系统是被动地收集用户的行为信息的，我们只能猜测用户的偏好和真实意图。比如说，我们可以分析用户的购买行为，但这不意味着用户就是喜欢这个商品的。可能这次购买只是用户买给别人的礼物，或者用户购买使用之后，并不喜欢这个商品。另外，用户可能用户在某个时间看了某个视频，但是可能用户当时是睡着的，并不是有意去看这个视频的
3. 在显性反馈数据中，数值的大小可以反映偏好，但是在隐性反馈系统中，数值大小只能反映置信度（confidence）
    显性反馈系统中，用户的评分高代表，用户的偏好更高。在隐性反馈系统中呢，数值只代表用户行为的频次和频率（用户购买的次数，用户的购买行为是否频繁）。例如，有可能用户最喜欢的电影，他只看了一次，但是另一部还不错的剧，用户可能每周都在追。
    但尽管如此，隐形反馈的数值还是很有用，它代表用户行为的置信度。一次性的行为有可能是用户无疑的动作，和偏好没有关系，但是重复发生的行为更可能代表用户的偏好
4. 对用户隐性反馈的评价需要挑选合适的指标
    在常规的用户打分模型中，我们就有明确的指标可以使用（均方差），来评价算法的好坏。但是在隐形反馈模型中，我们需要考虑用户对这个商品的可达性，商品之间的互相影响，和重复反馈等等。

# Preliminaries 准备工作
我们用特定的字母来标记用户和物品：
1. 用户用 $u$ 和 $v$
2. 商品用 $i$ 和 $j$
3. 输入的用户对商品的行为记为  $r\_{ui}$

在显性反馈模型中，这就是用户的评分信息；在隐性反馈模型中，就是用户的行为信息，例如可以代表，用户对商品的购买次数，或者用户在页面的停留时间。在我们的视频推荐系统中，$r\_{ui}$ 就代表用户 $u$ 完整观看 $i$ 的次数。如果 $r\_{ui}=0.7$，就代表用户看了这个视频 70% 的内容；如果 $r\_{ui}$ ，就代表用户看这个视频看了两遍。

在评分模型中，用户对大部分用商品都是没有评分的，所以数据是缺失的。但是在隐性反馈模型中，当 $r\_{ui}$ 缺失的时候，很自然它的值就是 0，表示用户没有看过这个视频，或用户买有购买过这个商品。

# Previous work 过去的研究

**领域模型 neighbohood model**
最常用的 CF 算法就是基于领域模型做的。早期几乎所有的 CF 推荐系统都是基于用户的方法做的，是通过相似用户来预测评分。后来呢，基于商品的 CF 开始流行，提升了可伸缩性和准确性。 而且，基于商品的协同过滤推荐更有效地提供了预测背后的解释，因为用户对之前喜欢过的商品是熟知的，但是可能并不认识和他们相似的用户。

基于商品的协同过滤推荐的核心就是商品之间的相似关系，我们用 $s\_{ij}$ 来标记，$i$，$j$之间的相似度。通常来说，这个相似度可以用**皮尔逊相似来计算**。我们的目标是预测 $r\_{ui}$ 也就是用户 $u$ 对 商品 $i$ 的评分。

对于用户 $u$ 打分过得 $k$ 个与商品 $i$ 最相似的商品，也就是商品 $i$ 的领域，我们记为 $S^k\_{i:u}$。那我们的预测值 $r\_{ui}$ 就是对领域商品的加权评分

>此处算加权，要先选出商品 i 的领域，之前没考虑


$$ \hat{r}\_{ui} = 
   \frac{ \sum\_{j \in S^k(i;u)} S\_{ij} r\_{uj}  }
   {\sum\_{j \in S^k(i;u)} S\_{ij}}    
$$


在显性反馈模型中，对这个算法有很多改进，比如说，修正因为不同用户，不同商品的平均打分情况带来的偏差。

>比如用户A对买过商品的平均打分就是3.5分，用户B对买过商品的平均打分就是4.5分。那么他们对同一个商品都打了4分，就代表了不同的偏好含义。

但是这些修正在隐形反馈模型中相对并不重要，因为我们只使用用户行为的频率，而不是固定范围内的打分。不同用户的行为频次差别可能会很大，而且如何计算相似度会更不明确。

所有使用隐性反馈信息的基于商品的模型都有一个缺点：在如何区分用户的偏好和用户偏好的置信度上并不灵活。

**latent factor model 潜在因子模型**

潜在因子模型相对于协同过滤的方法，有一个更全面局的目标，去找潜在影响用户评分的因素，例如 pSLA，神经网络（neural network），潜在狄利克雷分布（latent dirichlet allocation）。我们重点关注对用户商品的奇异值分解SVD（Singular Value Decomposition）。由于SVD不错的准确度和可伸缩性，SVD变得越来越流行。

一个典型的模型是：
1. 用户 $u$ 有一个用户向量：$x_u \in R^f$
2. 商品 $i$ 有一个商品向量：$y_i \in R^f$

我们的预测是通过两个向量的内积（Inner Product）完成的 $\hat{r}_{ui} = x^T_uy^i$，这个过程中更复杂的部分是参数估计（parameter estimation）。最近很多的进展都是利用了显性反馈信息，并且利用了一个充分的正规化模型来避免过拟合，

# Our Model 我们的模型

在这一节，我们来讨论我们的模型。

首先，我们要对用户对商品的打分 $r\_{ui}$ 确定一个可衡量的置信度。我们引入一个二元变量 $p\_{ui}$，这个变量代表了用户对商品的偏好，这个变量就是利用 $r\_{ui}$ 得到的

$$
p\_{ui} = 
\begin{cases}
    1,& r\_{ui} > 0 \\\\
    0,& r\_{ui} = 0 
\end{cases}
$$


举个例子，
1. 当用户购买了一个商品的时候（$r\_{ui} >0 $），那我们就推断这个用户对这个商品的是感兴趣的（$p\_{ui} = 1$）
2. 当用户对某个商品没有任何行为，那我们推断用户对这个商品没有兴趣（$p\_{ui} = 0$）

那事实上，我们的推断应该基于不同层级的置信度，这里只有二元。
1. $p\_{ui} = 0$ ，应该指的是用户对商品有偏好的置信度相对低。用户对商品没有任何正向的行为，除了用户不喜欢这个商品以外，可能的原因还有很多种。比如，用户可能没有意识到这个商品的存在，或者觉得这个商品价格太高，或者单纯地没找到这个商品。
2. 除此之外，用户对商品有行为，也可能是出于别的原因，而一定是用户就喜欢这个商品。例如说，用户看了一个视频，可能只是因为用户停留在这个频道，视频自动播放了，而用户根本就没在看。或者用户买了个商品，是因为朋友喜欢，所以买了一个当做礼物。

所以，用户对商品的偏好应该有不同层级的置信度。换言之，随着 $r\_{ui}$ 的增长，我们有更强的理由相信，用户就是喜欢这个商品的。所以，我们引入一个变量集合 $c\_{ui}$ ，来衡量我们对 $p\_{ui}$ 的置信度。

$$
c\_{ui} = 1 + \alpha r\_{ui}
$$

这样的话，每个用户-商品配对就有了一个基本的置信度 $p\_{ui} = =1 $，然后随着我们观察到用户对商品又更多的正向行为，我们的置信度 $p\_{ui}$ 会随之增长，增长的复读，由常量 $\alpha$ 决定。在我们的实验中，我们发现 $\alpha  = 40$ 是一个不错的设定。

我们的目标是
1. 针对每一个用户 $u$ 找到一个向量 $x_u \in R^f$ ，(User factor)
2. 针对每一个商品 $i$ 找到一个向量 $y_i \in R^f$ ，(Item factor)
3. 这两个向量可以代表代表用户的偏好

换言之，用户的偏好是由这两个向量的内积得出的 $p\_{ui} = x^T_uy_i$

本质上，这些向量是想办法将用户和商品映射到一个共同的潜在因素空间，在这里可以直接互相比较。这和矩阵分解类似，矩阵分解经常被用在显性反馈中。但是有两个重要的区别：
1. 我们需要设置不同的置信度
2. 我们需要对所有的用户商品对进行优化，而不是显性数据（相对来说是一个较小的集合）

相对应的，我们需要计算下列代价函数（cost function）的最小值：
$$
min\_{x\*,y\*} \sum\_{u,i} c\_{ui}(p\_{ui}-x^T_uy_i)^2 + \lambda(\sum\_u \Arrowvert x\_u \Arrowvert ^2 +  \sum\_i \Arrowvert y\_i \Arrowvert ^2)  
$$

> (- -)!  Markdown 中的“_斜体_”语法和 latex的 “\\_” 冲突，要记得转义

$\lambda(\sum\_u \Arrowvert x\_u \Arrowvert ^2 +  \sum\_i \Arrowvert y\_i \Arrowvert ^2) $ 是用来对模型进行正规化的，防止数据过拟合 $\lambda$ 的具体数值需要对具体的数据进行验证来确定。

我们的代价方程，包含 $m·n$ 项，$m$ 代表用户的数量，$n$ 代表商品的数量。所以在数据的量级上，很容易达到数十亿的量级，如此巨大的量级让我们很难使用一些直接的优化方法，例如，随机梯度下降（stochastic gradient descent）。因此，我们推荐使用另一种更有效的优化方法。

由于我们的用户因子和商品因子都是固定的，所以我们的代价方程就是二次的，所以它的全局最小值是可以很容易地计算出来的。我们使用交替最小二乘（alternating least square）优化方法。我们交替计算用户因子，和商品因子，每一步都保证代价方程的值都是更低的。

在显性反馈模型中，交替最小二乘把未知的值当做丢失数据来处理，所以处理的是一个稀疏目标方程。但是在隐性反馈模型中，我们需要解决更数据密集的目标方程，并且需要融入置信度等级。我们通过研究变量的结构来解决这个问题，以保证高伸缩性：

第一步，我们需要重新计算所有的用户因子。我们假设所有的商品因子都落在 $ n \times f$ 的矩阵 $Y$ 中，在对所有的用户做循环计算之前，我们计算 $f \times f$ 矩阵 $Y^TY$ ，时间复杂度是 $O(f^2n)$。

> $f$ 指的是，商品的特征有 $f$ 个维度
> $Y^f·Y = f\times n · n \times f = f \times f$ 
> 时间复杂度是 $O(f·f·n)=O(f^2n)$
 
对于每个用户 $u$ 我们定义$n \times n$的对角矩阵 $C^u$，其中$C^u\_{ii} = c\_{ui}$，向量$p(u) \in R^n$ 。通过微分，我们可以得到，最小化代价函数的表达式时的 $x_u$

$$
x_u = (Y^TC^uY+\lambda I)^{-1}Y^TC^up(u)
$$

这个地方的计算瓶颈就是 $Y^TC^uY$ ，计算复杂度是 $O(f^2·n)$
但是，一个能够利用的提升性能的办法就是：$Y^TC^uY = Y^TY+Y^T(C^u-I)Y$。

1. $Y^TY$ 是独立于 $u$ 的，是事先计算好的。
2. 至于 $Y^T(C^u-I)Y$ 呢，$C^u-I$ 只有 $n\_u$ 个非零元素，也就是要用户打分大于 0（ $r\_{ui} > 0$） 的商品数量，通常来说 $n_u \ll n$。类似的，$C^u p(u)$ 也只有 $n_u$ 个非零元素。
3. 接下来，$x_u$ 的重新计算的复杂度在 $O(f^2n\_u+f^3)$，我们假设矩阵求逆的计算 $(Y^TC^uY + \lambda I$ $O(f^3))^(-1)$ 的时间复杂度是 $O(f^3)$，尽管有更加高效的算法可以用，但是在 $f$ 是很小的量级的情况下，帮助也就没那么大了。
4. 这个步骤对所有 $m$ 个用户都要分别做过，所以总共的时间复杂度是 $O(f^2 \mathcal{N}+f^3m)$，$\mathcal{N}$代表的是非零数据的总和，也就是 $\mathcal N = \sum\_u n\_u$。重要的是，时间复杂度和输入是呈线性关系。通常来说，$f$ 的取值在 20 到 200 之间。

在优化完商品特征矩阵以后，我们就要来优化用户特征矩阵了。我们把所有的用户特征放到一个 $m \times f$ 的矩阵 $X$ 中去。

首先我们计算 $f \times f$ 维的矩阵 $X^TX$，时间复杂度是 $O(f^2m)$。对于每个商品 $i$，我们定义 $m \times m$ 维的对角矩阵，$C^i$，$C\_{ii}^u = c_{ui}$。同样，向量 $p(i) \in R^m$。然后我们求导得到

$$y_i = (X^TC^iX + \lambda I)^{-1}X^TC^ip(i)$$

运用相同的方法，我们可以在 $O(f^2\mathcal{N} + f^3 n)$ 的时间复杂度内做完这一步操作。我们还可以在去除一些重复计算的用户特征矩阵和商品特征矩阵，直到稳定为止。一个常用的剔除数量是10。整个操作都是随着数据集的增长呈线性复杂度增长的。

在计算完用户的特征矩阵和商品的特征矩阵之后，我们推荐给用户 $u$ 前 $K$ 个 $\hat{p}\_{ui} = X^T\_u y\_i$ 最大的商品，$\hat{p}\_{ui}$ 代表着用户 $u$ 对商品 $i$ 的偏好。

现在呢，我们的操作的基本描述都已经讨论完了，我们需要进一步深入探讨，因为一些策略可以稍作调整。




















